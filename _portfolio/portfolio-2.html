---
title: "LLM Understanding of Intermediate Representations"
collection: portfolio
excerpt: "Pioneering empirical study investigating LLM capabilities in understanding Intermediate Representations (IRs) for compiler design and program analysis."
date: 2025-02-01
image: 
  path: /images/llm-ir-understanding.jpg
  alt: "LLM IR Understanding Research"
links:
  - label: "Paper"
    url: "https://arxiv.org/abs/2502.06854"
  - label: "arXiv"
    url: "https://arxiv.org/abs/2502.06854"
---

<div class="portfolio-item">
  <h3>Project Overview</h3>
  <p>This research project investigates the capabilities of Large Language Models (LLMs) in understanding Intermediate Representations (IRs), which are essential in compiler design and program analysis. The study addresses a critical gap in our understanding of how modern AI models handle low-level code representations.</p>
  
  <h3>Research Objectives</h3>
  <ul>
    <li><strong>IR Comprehension Analysis</strong>: Evaluate LLM understanding of IR syntax and semantics</li>
    <li><strong>Task Performance Assessment</strong>: Test LLMs across four critical IR-related tasks</li>
    <li><strong>Model Comparison</strong>: Analyze performance differences between various LLM architectures</li>
    <li><strong>Enhancement Recommendations</strong>: Propose improvements for IR-specific LLM capabilities</li>
  </ul>
  
  <h3>Methodology</h3>
  <ul>
    <li><strong>Models Tested</strong>: GPT-4, GPT-3, Gemma 2, LLaMA 3.1, and Code Llama</li>
    <li><strong>Evaluation Tasks</strong>: Control Flow Graph (CFG) reconstruction, decompilation, code summarization, and execution reasoning</li>
    <li><strong>Analysis Framework</strong>: Comprehensive empirical study with structured evaluation metrics</li>
    <li><strong>IR Dataset</strong>: Diverse Intermediate Representation samples for testing</li>
  </ul>
  
  <h3>Key Findings</h3>
  <ul>
    <li><strong>Strengths</strong>: LLMs demonstrate competence in parsing IR syntax and recognizing high-level structures</li>
    <li><strong>Limitations</strong>: Struggle with control flow reasoning, execution semantics, and loop handling</li>
    <li><strong>Common Errors</strong>: Misinterpretation of branching instructions, omission of critical IR operations</li>
    <li><strong>Reasoning Patterns</strong>: Heavy reliance on heuristic-based reasoning rather than deep understanding</li>
  </ul>
  
  <h3>Research Impact</h3>
  <p>This study provides foundational insights into LLM capabilities for compiler-level tasks and program analysis, with implications for:</p>
  <ul>
    <li>AI-assisted compiler development</li>
    <li>Program analysis automation</li>
    <li>LLM training for low-level code understanding</li>
    <li>Integration of AI in software engineering tools</li>
  </ul>
  
  <h3>Technical Contributions</h3>
  <ul>
    <li>Novel evaluation framework for IR comprehension</li>
    <li>Comprehensive analysis of LLM limitations in IR tasks</li>
    <li>Specific recommendations for IR-specific LLM enhancements</li>
    <li>Framework for future research in AI-driven program analysis</li>
  </ul>
  
  <h3>Future Directions</h3>
  <p>The research identifies several areas for improvement:</p>
  <ul>
    <li>IR-specific fine-tuning on structured datasets</li>
    <li>Integration of explicit control flow models</li>
    <li>Enhanced training on compiler-level tasks</li>
    <li>Development of specialized IR understanding models</li>
  </ul>
  
  <h3>Publication</h3>
  <p>This work has been published as an arXiv preprint: <a href="https://arxiv.org/abs/2502.06854" target="_blank">"Can Large Language Models Understand Intermediate Representations?"</a></p>
</div> 
